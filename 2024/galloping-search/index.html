<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=generator content="Hugo 0.139.4"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content><meta property="og:url" content="https://avi.im/blag/2024/galloping-search/"><title>Galloping Search - blag</title>
<meta property="og:title" content="Galloping Search - blag"><meta property="og:type" content="article"><meta property="og:description" content="I recently learned about Galloping Search while building a distributed log called s3-log. It&rsquo;s used to search sorted items when the upper bound is unknown. In this short post, I will share my notes and other alternatives I discovered for searching over unbounded items"><meta name=description content="I recently learned about Galloping Search while building a distributed log called s3-log. It&rsquo;s used to search sorted items when the upper bound is unknown. In this short post, I will share my notes and other alternatives I discovered for searching over unbounded items"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Source+Code+Pro|Arvo:400,700"><link rel=stylesheet href=/blag/css/highlight.css><link rel=stylesheet href=/blag/css/journal.css><link href=/blag/index.xml rel=alternate type=application/rss+xml title=blag></head><body><div class=container><div class=site-header-nav><nav class=site-nav><a href=https://avi.im/blag/>Index</a></nav><div><span><a href=/blag/about>About</a></span>
<span><a href=/blag/now>Now</a></span></div></div><article class=post><header class=post-header><h1 class=post-title>Galloping Search</h1><time class=post-date datetime="2024-12-07 16:41:34 +0530">07 Dec 2024</time></header><p>I recently learned about an algorithm called Galloping Search. It&rsquo;s used to search sorted items when the upper bound is unknown. It&rsquo;s like binary search but without the &lsquo;high&rsquo; value. In this short post, I&rsquo;ll explain my problem and how I solved it.</p><p>I am building a <a href=https://avi.im/blag/2024/s3-log>distributed log over S3</a>. In a bucket or directory, I continuously add files named with sequential integers:</p><img src=/blag/images/2024/s3-bucket.svg alt="s3 bucket" style=width:80%><p>The writer keeps a counter in memory. On each insert request, the writer increments the counter, assigning a unique sequential number to the new object. There are no gaps. If the machine crashes, I need a way to locate the last inserted objectâ€”the one with the highest number.</p><p>S3&rsquo;s limitations make this challenging:</p><ul><li>S3 has no API to fetch the last inserted item.</li><li>The LIST API doesn&rsquo;t support sorting; it always returns results in lexicographical order.</li><li>I don&rsquo;t want to scan the entire bucket of hundreds of thousands of items because the S3 LIST API is expensive (it costs the same as a PUT!).</li></ul><h3 id=solution>Solution</h3><p>Hereâ€™s what I came up with: I search for objects at exponential intervals (1,000th, 10k, 50k, 100k) in parallel. When I find a gap (e.g., 100k missing but 50k exists), I binary search that range (e.g., 60k, 75k, 90k) until I narrow it to a manageable gap (5â€“10k objects). Then I use S3&rsquo;s LIST API to fetch objects from that point.</p><img src=/blag/images/2024/galloping-search.svg alt="galloping search"><p>Turns out this is called <a href=https://en.wikipedia.org/wiki/Exponential_search>Exponential Search (or Galloping Search)</a>:</p><blockquote><p>Exponential search allows for searching through a sorted, unbounded list for a specified input value (the search &ldquo;key&rdquo;). The algorithm consists of two stages. The first stage determines a range in which the search key would reside if it were in the list. In the second stage, a binary search is performed on this range.</p></blockquote><p>When I posted <a href=https://x.com/iavins/status/1863205355443953930>this online</a>, there were lots of questions, and many people offered alternative solutions to find the largest number:</p><ul><li>The most common (and boring) answer was to keep a counter in a local file or SQLite database. This doesnâ€™t work because itâ€™s not helpful if my machine crashes and I need to recover from S3.</li><li>Use DynamoDB, Redis, or another database: This works but also kinda sucks because I don&rsquo;t want to add another dependency to my library. Itâ€™s better if everything is self-contained in S3.</li><li>Store a counter in S3 and update it at every write: This adds write amplification, and S3 PUT costs are expensive. Iâ€™d essentially pay twice for each write!</li><li>Use ULID/UUID/Timestamps: This doesnâ€™t work because I would lose point lookups. I want numbers to be sequential.</li></ul><h3 id=alternate-solutions>Alternate Solutions</h3><ul><li><p>Inverse Sequencing: Store a counter starting from the maximum value (<code>u64::max</code>) and decrement it with each insert. The S3 LIST API is lexicographical, so you always get the last inserted filename with a single list call. I am split on this solution as I find it cognitively taxing.</p></li><li><p><a href=https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-prefixes.html>Partitioning and Hierarchical Search</a>: Store objects with partitioning using a delimiter like <code>000/042/001</code>. When you partition, the LIST API returns only the top hierarchy results (if you pass the delimiter <code>/</code> in the search request). For 100,000,000 (100M) files, it only takes 3 requests to find the largest number since the LIST API can return up to 1,000 items. For comparison, it is 50+ calls even when I use Galloping Search.</p></li></ul><h3 id=what-im-doing>What Iâ€™m Doing</h3><ol><li>At every 10k or 50k writes, I write the current count in a file called <code>.metadata</code>. This reduces both cost and write amplification. I call this the checkpointing operation.</li><li>While searching, I start from the counter in the <code>.metadata</code> file. Then I perform the Galloping Search. Even if the metadata file doesnâ€™t exist, the approach still works.</li></ol><p>After checkpointing, gaps may exist in the files preceding the last checkpointed number, but this does not impact its effectiveness. For now, Iâ€™m happy with the approach, though I may move to checkpointing + partitioning in the future.</p><hr><p><small>1. Thanks to folks @0xriggler and @JustinWaugh on X (formerly known as Twitter) for telling me about partitioning search.</small><br><small>2. The <a href=https://github.com/avinassh/s3-log>s3-log project</a> is open source.</small><br><small>3. I use S3&rsquo;s conditional write to &ldquo;append&rdquo; and add a new object with the next sequence number.</small><br><small>4. Having gaps in the log can be catastrophic. A writer may add a new object at the gap and return success to the client ðŸ’€</small><br></p></article><script async data-uid=0576bb9e32 src=https://avin.ck.page/0576bb9e32/index.js></script><footer class=site-footer><div class=rc-scout style=margin-right:auto;margin-top:auto;font-size:.6rem></div><script async defer src="https://www.recurse-scout.com/loader.js?t=a4aabd5087bb19daf083302de1b46650"></script><span class=person-schema itemscope itemtype=http://schema.org/Person><link itemprop=url href=https://avi.im/blag/><span itemprop=name></span><br><a itemprop=sameAs href=https://github.com/avinassh title=GitHub><img src=/blag/svg/gh.svg alt="icon name"></a>
<a itemprop=sameAs href=/blag/index.xml title=GitHub><img src=/blag/svg/rss.svg alt="icon name"></a></span></footer></div><script src=/blag/js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad()</script><script data-goatcounter=https://avi.goatcounter.com/count async src=//gc.zgo.at/count.js></script></body></html>